{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import gc\n",
    "from path import Path\n",
    "import numpy as np\n",
    "from memory_profiler import memory_usage\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('Train_song/train.csv',dtype=str)\n",
    "test=pd.read_csv('Test_song/test.csv',dtype=str)\n",
    "\n",
    "train['ID'] = train['ID']+'.jpg'\n",
    "test['ID'] = test['ID']+'.jpg'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4077 validated image filenames belonging to 10 classes.\n",
      "Found 1358 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "img_datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "\n",
    "\n",
    "train_generator=img_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=\"Train_song/Specto\",\n",
    "    x_col=\"ID\",\n",
    "    y_col=\"Class\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=48,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64,64))\n",
    "\n",
    "valid_generator=img_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=\"Train_song/Specto\",\n",
    "    x_col=\"ID\",\n",
    "    y_col=\"Class\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=32,\n",
    "    seed=48,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 390,986\n",
      "Trainable params: 390,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu',input_shape=(64,64,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "127/127 [==============================] - 20s 158ms/step - loss: 1.9414 - accuracy: 0.2710 - val_loss: 1.7962 - val_accuracy: 0.3996\n",
      "Epoch 2/200\n",
      "127/127 [==============================] - 22s 170ms/step - loss: 1.4933 - accuracy: 0.4643 - val_loss: 1.2467 - val_accuracy: 0.4925\n",
      "Epoch 3/200\n",
      "127/127 [==============================] - 21s 163ms/step - loss: 1.2837 - accuracy: 0.5491 - val_loss: 1.3895 - val_accuracy: 0.5739\n",
      "Epoch 4/200\n",
      "127/127 [==============================] - 21s 166ms/step - loss: 1.1151 - accuracy: 0.6222 - val_loss: 1.0693 - val_accuracy: 0.6018\n",
      "Epoch 5/200\n",
      "127/127 [==============================] - 23s 183ms/step - loss: 0.9641 - accuracy: 0.6752 - val_loss: 0.8110 - val_accuracy: 0.6968\n",
      "Epoch 6/200\n",
      "127/127 [==============================] - 24s 185ms/step - loss: 0.8375 - accuracy: 0.7283 - val_loss: 0.8076 - val_accuracy: 0.6825\n",
      "Epoch 7/200\n",
      "127/127 [==============================] - 22s 177ms/step - loss: 0.7822 - accuracy: 0.7402 - val_loss: 0.5759 - val_accuracy: 0.7730\n",
      "Epoch 8/200\n",
      "127/127 [==============================] - 22s 175ms/step - loss: 0.7017 - accuracy: 0.7622 - val_loss: 0.5709 - val_accuracy: 0.7647\n",
      "Epoch 9/200\n",
      "127/127 [==============================] - 22s 176ms/step - loss: 0.6213 - accuracy: 0.7933 - val_loss: 0.7507 - val_accuracy: 0.7677\n",
      "Epoch 10/200\n",
      "127/127 [==============================] - 23s 177ms/step - loss: 0.5828 - accuracy: 0.8109 - val_loss: 0.5023 - val_accuracy: 0.7858\n",
      "Epoch 11/200\n",
      "127/127 [==============================] - 23s 180ms/step - loss: 0.5397 - accuracy: 0.8205 - val_loss: 0.9099 - val_accuracy: 0.7858\n",
      "Epoch 12/200\n",
      "127/127 [==============================] - 23s 184ms/step - loss: 0.4791 - accuracy: 0.8423 - val_loss: 0.5715 - val_accuracy: 0.8235\n",
      "Epoch 13/200\n",
      "127/127 [==============================] - 23s 182ms/step - loss: 0.4537 - accuracy: 0.8499 - val_loss: 0.8151 - val_accuracy: 0.8371\n",
      "Epoch 14/200\n",
      "127/127 [==============================] - 23s 184ms/step - loss: 0.4227 - accuracy: 0.8561 - val_loss: 0.6789 - val_accuracy: 0.8258\n",
      "Epoch 15/200\n",
      "127/127 [==============================] - 24s 187ms/step - loss: 0.4043 - accuracy: 0.8670 - val_loss: 0.4281 - val_accuracy: 0.8348\n",
      "Epoch 16/200\n",
      "127/127 [==============================] - 24s 186ms/step - loss: 0.3638 - accuracy: 0.8769 - val_loss: 0.5940 - val_accuracy: 0.8499\n",
      "Epoch 17/200\n",
      "127/127 [==============================] - 25s 195ms/step - loss: 0.3793 - accuracy: 0.8756 - val_loss: 0.2687 - val_accuracy: 0.8424\n",
      "Epoch 18/200\n",
      "127/127 [==============================] - 25s 198ms/step - loss: 0.3404 - accuracy: 0.8883 - val_loss: 0.3471 - val_accuracy: 0.8567\n",
      "Epoch 19/200\n",
      "127/127 [==============================] - 25s 194ms/step - loss: 0.3220 - accuracy: 0.8915 - val_loss: 0.6927 - val_accuracy: 0.8356\n",
      "Epoch 20/200\n",
      "127/127 [==============================] - 25s 195ms/step - loss: 0.2917 - accuracy: 0.9014 - val_loss: 0.5044 - val_accuracy: 0.8605\n",
      "Epoch 21/200\n",
      "127/127 [==============================] - 25s 200ms/step - loss: 0.2811 - accuracy: 0.9058 - val_loss: 0.7109 - val_accuracy: 0.8650\n",
      "Epoch 22/200\n",
      "127/127 [==============================] - 26s 203ms/step - loss: 0.2536 - accuracy: 0.9147 - val_loss: 0.4986 - val_accuracy: 0.8575\n",
      "Epoch 23/200\n",
      "127/127 [==============================] - 26s 206ms/step - loss: 0.2525 - accuracy: 0.9110 - val_loss: 0.3902 - val_accuracy: 0.8409\n",
      "Epoch 24/200\n",
      "127/127 [==============================] - 27s 210ms/step - loss: 0.2283 - accuracy: 0.9288 - val_loss: 0.4978 - val_accuracy: 0.8544\n",
      "Epoch 25/200\n",
      "127/127 [==============================] - 27s 216ms/step - loss: 0.2234 - accuracy: 0.9216 - val_loss: 0.3949 - val_accuracy: 0.8808\n",
      "Epoch 26/200\n",
      "127/127 [==============================] - 28s 221ms/step - loss: 0.2130 - accuracy: 0.9281 - val_loss: 0.4435 - val_accuracy: 0.8567\n",
      "Epoch 27/200\n",
      "127/127 [==============================] - 29s 226ms/step - loss: 0.2009 - accuracy: 0.9295 - val_loss: 0.1607 - val_accuracy: 0.8771\n",
      "Epoch 28/200\n",
      "127/127 [==============================] - 29s 229ms/step - loss: 0.1801 - accuracy: 0.9387 - val_loss: 0.5890 - val_accuracy: 0.8597\n",
      "Epoch 29/200\n",
      "127/127 [==============================] - 27s 214ms/step - loss: 0.1814 - accuracy: 0.9384 - val_loss: 0.4489 - val_accuracy: 0.8703\n",
      "Epoch 30/200\n",
      "127/127 [==============================] - 27s 209ms/step - loss: 0.1844 - accuracy: 0.9373 - val_loss: 0.3886 - val_accuracy: 0.8718\n",
      "Epoch 31/200\n",
      "127/127 [==============================] - 26s 204ms/step - loss: 0.1703 - accuracy: 0.9404 - val_loss: 0.5508 - val_accuracy: 0.8673\n",
      "Epoch 32/200\n",
      "127/127 [==============================] - 26s 205ms/step - loss: 0.1502 - accuracy: 0.9466 - val_loss: 0.1819 - val_accuracy: 0.8741\n",
      "Epoch 33/200\n",
      "127/127 [==============================] - 26s 207ms/step - loss: 0.1556 - accuracy: 0.9461 - val_loss: 0.3915 - val_accuracy: 0.8522\n",
      "Epoch 34/200\n",
      "127/127 [==============================] - 27s 209ms/step - loss: 0.1291 - accuracy: 0.9562 - val_loss: 0.9094 - val_accuracy: 0.8703\n",
      "Epoch 35/200\n",
      "127/127 [==============================] - 27s 211ms/step - loss: 0.1575 - accuracy: 0.9441 - val_loss: 0.4804 - val_accuracy: 0.8658\n",
      "Epoch 36/200\n",
      "127/127 [==============================] - 28s 221ms/step - loss: 0.1625 - accuracy: 0.9464 - val_loss: 0.1850 - val_accuracy: 0.8763\n",
      "Epoch 37/200\n",
      "127/127 [==============================] - 27s 212ms/step - loss: 0.1568 - accuracy: 0.9481 - val_loss: 0.4545 - val_accuracy: 0.8688\n",
      "Epoch 38/200\n",
      "127/127 [==============================] - 26s 209ms/step - loss: 0.1142 - accuracy: 0.9633 - val_loss: 0.4737 - val_accuracy: 0.8756\n",
      "Epoch 39/200\n",
      "127/127 [==============================] - 27s 210ms/step - loss: 0.1131 - accuracy: 0.9647 - val_loss: 0.1581 - val_accuracy: 0.8643\n",
      "Epoch 40/200\n",
      "127/127 [==============================] - 27s 211ms/step - loss: 0.1242 - accuracy: 0.9582 - val_loss: 0.4790 - val_accuracy: 0.8763\n",
      "Epoch 41/200\n",
      "127/127 [==============================] - 28s 218ms/step - loss: 0.1222 - accuracy: 0.9572 - val_loss: 0.1933 - val_accuracy: 0.8808\n",
      "Epoch 42/200\n",
      "127/127 [==============================] - 27s 212ms/step - loss: 0.1159 - accuracy: 0.9629 - val_loss: 0.7460 - val_accuracy: 0.8831\n",
      "Epoch 43/200\n",
      "127/127 [==============================] - 26s 203ms/step - loss: 0.1484 - accuracy: 0.9488 - val_loss: 0.8156 - val_accuracy: 0.8756\n",
      "Epoch 44/200\n",
      "127/127 [==============================] - 26s 208ms/step - loss: 0.0952 - accuracy: 0.9695 - val_loss: 0.0891 - val_accuracy: 0.8943\n",
      "Epoch 45/200\n",
      "127/127 [==============================] - 27s 215ms/step - loss: 0.0849 - accuracy: 0.9719 - val_loss: 0.1753 - val_accuracy: 0.8816\n",
      "Epoch 46/200\n",
      "127/127 [==============================] - 31s 241ms/step - loss: 0.0807 - accuracy: 0.9726 - val_loss: 0.5566 - val_accuracy: 0.8763\n",
      "Epoch 47/200\n",
      "127/127 [==============================] - 27s 216ms/step - loss: 0.0941 - accuracy: 0.9717 - val_loss: 0.4310 - val_accuracy: 0.8741\n",
      "Epoch 48/200\n",
      "127/127 [==============================] - 26s 205ms/step - loss: 0.0850 - accuracy: 0.9722 - val_loss: 0.6282 - val_accuracy: 0.8801\n",
      "Epoch 49/200\n",
      "127/127 [==============================] - 27s 214ms/step - loss: 0.0839 - accuracy: 0.9708 - val_loss: 0.7644 - val_accuracy: 0.8846\n",
      "Epoch 50/200\n",
      "127/127 [==============================] - 27s 214ms/step - loss: 0.0986 - accuracy: 0.9684 - val_loss: 0.4961 - val_accuracy: 0.8839\n",
      "Epoch 51/200\n",
      "127/127 [==============================] - 28s 221ms/step - loss: 0.0898 - accuracy: 0.9718 - val_loss: 0.9207 - val_accuracy: 0.8884\n",
      "Epoch 52/200\n",
      "127/127 [==============================] - 29s 225ms/step - loss: 0.0842 - accuracy: 0.9715 - val_loss: 0.4175 - val_accuracy: 0.8876\n",
      "Epoch 53/200\n",
      "127/127 [==============================] - 29s 229ms/step - loss: 0.0952 - accuracy: 0.9674 - val_loss: 1.2057 - val_accuracy: 0.8914\n",
      "Epoch 54/200\n",
      "127/127 [==============================] - 27s 211ms/step - loss: 0.0834 - accuracy: 0.9717 - val_loss: 0.7791 - val_accuracy: 0.8914\n",
      "Epoch 55/200\n",
      "127/127 [==============================] - 30s 233ms/step - loss: 0.0884 - accuracy: 0.9692 - val_loss: 0.3293 - val_accuracy: 0.8891\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 28s 219ms/step - loss: 0.0653 - accuracy: 0.9759 - val_loss: 0.9161 - val_accuracy: 0.8861\n",
      "Epoch 57/200\n",
      "127/127 [==============================] - 26s 206ms/step - loss: 0.0688 - accuracy: 0.9773 - val_loss: 0.5588 - val_accuracy: 0.8884\n",
      "Epoch 58/200\n",
      "127/127 [==============================] - 26s 204ms/step - loss: 0.0858 - accuracy: 0.9718 - val_loss: 0.5907 - val_accuracy: 0.8854\n",
      "Epoch 59/200\n",
      "127/127 [==============================] - 27s 210ms/step - loss: 0.0766 - accuracy: 0.9760 - val_loss: 0.5819 - val_accuracy: 0.8808\n",
      "Epoch 60/200\n",
      "127/127 [==============================] - 28s 222ms/step - loss: 0.0776 - accuracy: 0.9735 - val_loss: 0.3409 - val_accuracy: 0.8741\n",
      "Epoch 61/200\n",
      "127/127 [==============================] - 29s 228ms/step - loss: 0.0816 - accuracy: 0.9711 - val_loss: 0.2984 - val_accuracy: 0.9005\n",
      "Epoch 62/200\n",
      "127/127 [==============================] - 28s 224ms/step - loss: 0.1101 - accuracy: 0.9679 - val_loss: 0.0353 - val_accuracy: 0.9042\n",
      "Epoch 63/200\n",
      "127/127 [==============================] - 28s 221ms/step - loss: 0.0665 - accuracy: 0.9776 - val_loss: 0.2741 - val_accuracy: 0.8839\n",
      "Epoch 64/200\n",
      "127/127 [==============================] - 27s 214ms/step - loss: 0.0610 - accuracy: 0.9792 - val_loss: 0.8123 - val_accuracy: 0.8884\n",
      "Epoch 65/200\n",
      "127/127 [==============================] - 27s 213ms/step - loss: 0.0569 - accuracy: 0.9790 - val_loss: 0.1583 - val_accuracy: 0.9087\n",
      "Epoch 66/200\n",
      "127/127 [==============================] - 28s 218ms/step - loss: 0.0771 - accuracy: 0.9727 - val_loss: 0.2619 - val_accuracy: 0.8831\n",
      "Epoch 67/200\n",
      "127/127 [==============================] - 29s 225ms/step - loss: 0.0749 - accuracy: 0.9743 - val_loss: 1.0083 - val_accuracy: 0.8846\n",
      "Epoch 68/200\n",
      "127/127 [==============================] - 28s 221ms/step - loss: 0.0463 - accuracy: 0.9835 - val_loss: 0.1204 - val_accuracy: 0.8967\n",
      "Epoch 69/200\n",
      "127/127 [==============================] - 26s 208ms/step - loss: 0.0821 - accuracy: 0.9717 - val_loss: 0.5314 - val_accuracy: 0.8801\n",
      "Epoch 70/200\n",
      "127/127 [==============================] - 28s 217ms/step - loss: 0.0547 - accuracy: 0.9825 - val_loss: 0.2270 - val_accuracy: 0.8763\n",
      "Epoch 71/200\n",
      "127/127 [==============================] - 28s 219ms/step - loss: 0.0558 - accuracy: 0.9839 - val_loss: 0.4407 - val_accuracy: 0.8884\n",
      "Epoch 72/200\n",
      "127/127 [==============================] - 26s 203ms/step - loss: 0.0674 - accuracy: 0.9794 - val_loss: 0.3835 - val_accuracy: 0.8808\n",
      "Epoch 73/200\n",
      "127/127 [==============================] - 27s 209ms/step - loss: 0.0561 - accuracy: 0.9833 - val_loss: 0.1342 - val_accuracy: 0.8876\n",
      "Epoch 74/200\n",
      "127/127 [==============================] - 27s 209ms/step - loss: 0.0576 - accuracy: 0.9809 - val_loss: 0.3202 - val_accuracy: 0.8620\n",
      "Epoch 75/200\n",
      "127/127 [==============================] - 27s 216ms/step - loss: 0.0576 - accuracy: 0.9818 - val_loss: 0.3027 - val_accuracy: 0.8937\n",
      "Epoch 76/200\n",
      "127/127 [==============================] - 28s 218ms/step - loss: 0.0678 - accuracy: 0.9781 - val_loss: 0.7493 - val_accuracy: 0.8763\n",
      "Epoch 77/200\n",
      "127/127 [==============================] - 29s 226ms/step - loss: 0.0475 - accuracy: 0.9837 - val_loss: 0.5728 - val_accuracy: 0.8922\n",
      "Epoch 78/200\n",
      "127/127 [==============================] - 28s 222ms/step - loss: 0.0641 - accuracy: 0.9786 - val_loss: 0.9295 - val_accuracy: 0.8914\n",
      "Epoch 79/200\n",
      "127/127 [==============================] - 27s 209ms/step - loss: 0.0914 - accuracy: 0.9702 - val_loss: 0.8841 - val_accuracy: 0.8959\n",
      "Epoch 80/200\n",
      "127/127 [==============================] - 27s 215ms/step - loss: 0.0651 - accuracy: 0.9822 - val_loss: 0.0457 - val_accuracy: 0.8914\n",
      "Epoch 81/200\n",
      "127/127 [==============================] - 28s 219ms/step - loss: 0.0498 - accuracy: 0.9857 - val_loss: 0.8478 - val_accuracy: 0.8876\n",
      "Epoch 82/200\n",
      "127/127 [==============================] - 26s 206ms/step - loss: 0.0623 - accuracy: 0.9811 - val_loss: 1.0365 - val_accuracy: 0.8997\n",
      "Epoch 83/200\n",
      "127/127 [==============================] - 26s 205ms/step - loss: 0.0671 - accuracy: 0.9807 - val_loss: 1.7622 - val_accuracy: 0.8703\n",
      "Epoch 84/200\n",
      "127/127 [==============================] - 27s 212ms/step - loss: 0.0482 - accuracy: 0.9862 - val_loss: 0.4445 - val_accuracy: 0.8891\n",
      "Epoch 85/200\n",
      "127/127 [==============================] - 27s 216ms/step - loss: 0.0427 - accuracy: 0.9871 - val_loss: 0.6133 - val_accuracy: 0.8922\n",
      "Epoch 86/200\n",
      "127/127 [==============================] - 27s 215ms/step - loss: 0.0524 - accuracy: 0.9820 - val_loss: 0.2234 - val_accuracy: 0.8839\n",
      "Epoch 87/200\n",
      "127/127 [==============================] - 26s 202ms/step - loss: 0.0422 - accuracy: 0.9857 - val_loss: 0.8353 - val_accuracy: 0.8854\n",
      "Epoch 88/200\n",
      "127/127 [==============================] - 27s 210ms/step - loss: 0.0560 - accuracy: 0.9829 - val_loss: 0.2119 - val_accuracy: 0.8914\n",
      "Epoch 89/200\n",
      "127/127 [==============================] - 27s 216ms/step - loss: 0.0442 - accuracy: 0.9874 - val_loss: 0.3525 - val_accuracy: 0.8922\n",
      "Epoch 90/200\n",
      "127/127 [==============================] - 28s 220ms/step - loss: 0.0796 - accuracy: 0.9753 - val_loss: 0.2995 - val_accuracy: 0.8854\n",
      "Epoch 91/200\n",
      "127/127 [==============================] - 28s 222ms/step - loss: 0.0317 - accuracy: 0.9906 - val_loss: 0.4404 - val_accuracy: 0.8959\n",
      "Epoch 92/200\n",
      "127/127 [==============================] - 29s 227ms/step - loss: 0.0935 - accuracy: 0.9742 - val_loss: 0.5147 - val_accuracy: 0.8763\n",
      "Epoch 93/200\n",
      "127/127 [==============================] - 28s 224ms/step - loss: 0.0690 - accuracy: 0.9806 - val_loss: 0.4908 - val_accuracy: 0.8876\n",
      "Epoch 94/200\n",
      "127/127 [==============================] - 27s 211ms/step - loss: 0.0527 - accuracy: 0.9837 - val_loss: 0.3478 - val_accuracy: 0.8801\n",
      "Epoch 95/200\n",
      "127/127 [==============================] - 25s 200ms/step - loss: 0.0429 - accuracy: 0.9852 - val_loss: 1.1944 - val_accuracy: 0.8876\n",
      "Epoch 96/200\n",
      "127/127 [==============================] - 26s 202ms/step - loss: 0.0464 - accuracy: 0.9837 - val_loss: 0.6820 - val_accuracy: 0.8914\n",
      "Epoch 97/200\n",
      "127/127 [==============================] - 26s 204ms/step - loss: 0.0495 - accuracy: 0.9834 - val_loss: 1.0807 - val_accuracy: 0.8703\n",
      "Epoch 98/200\n",
      "127/127 [==============================] - 27s 216ms/step - loss: 0.0704 - accuracy: 0.9759 - val_loss: 0.2789 - val_accuracy: 0.8854\n",
      "Epoch 99/200\n",
      "127/127 [==============================] - 28s 221ms/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 0.2353 - val_accuracy: 0.9027\n",
      "Epoch 100/200\n",
      "127/127 [==============================] - 28s 218ms/step - loss: 0.0374 - accuracy: 0.9876 - val_loss: 0.0518 - val_accuracy: 0.8937\n",
      "Epoch 101/200\n",
      "127/127 [==============================] - 27s 209ms/step - loss: 0.0483 - accuracy: 0.9834 - val_loss: 1.9320 - val_accuracy: 0.8937\n",
      "Epoch 102/200\n",
      "127/127 [==============================] - 25s 197ms/step - loss: 0.0691 - accuracy: 0.9785 - val_loss: 0.6046 - val_accuracy: 0.8718\n",
      "Epoch 103/200\n",
      "127/127 [==============================] - 25s 193ms/step - loss: 0.0620 - accuracy: 0.9827 - val_loss: 1.7635 - val_accuracy: 0.8673\n",
      "Epoch 104/200\n",
      "127/127 [==============================] - 24s 188ms/step - loss: 0.0410 - accuracy: 0.9876 - val_loss: 0.2720 - val_accuracy: 0.9065\n",
      "Epoch 105/200\n",
      "127/127 [==============================] - 24s 190ms/step - loss: 0.0351 - accuracy: 0.9896 - val_loss: 0.5887 - val_accuracy: 0.8831\n",
      "Epoch 106/200\n",
      "127/127 [==============================] - 26s 206ms/step - loss: 0.0364 - accuracy: 0.9865 - val_loss: 0.4975 - val_accuracy: 0.8756\n",
      "Epoch 107/200\n",
      "127/127 [==============================] - 29s 226ms/step - loss: 0.0412 - accuracy: 0.9854 - val_loss: 0.6975 - val_accuracy: 0.8778\n",
      "Epoch 108/200\n",
      "127/127 [==============================] - 30s 238ms/step - loss: 0.0317 - accuracy: 0.9913 - val_loss: 0.3836 - val_accuracy: 0.9005\n",
      "Epoch 109/200\n",
      "127/127 [==============================] - 31s 244ms/step - loss: 0.0420 - accuracy: 0.9874 - val_loss: 1.8267 - val_accuracy: 0.8861\n",
      "Epoch 110/200\n",
      "127/127 [==============================] - 29s 225ms/step - loss: 0.0446 - accuracy: 0.9876 - val_loss: 0.1652 - val_accuracy: 0.8944\n",
      "Epoch 111/200\n",
      "127/127 [==============================] - 33s 259ms/step - loss: 0.0356 - accuracy: 0.9867 - val_loss: 0.1888 - val_accuracy: 0.8801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "127/127 [==============================] - 30s 236ms/step - loss: 0.0467 - accuracy: 0.9844 - val_loss: 0.0823 - val_accuracy: 0.8839\n",
      "Epoch 113/200\n",
      "127/127 [==============================] - 26s 208ms/step - loss: 0.0384 - accuracy: 0.9871 - val_loss: 0.2962 - val_accuracy: 0.8997\n",
      "Epoch 114/200\n",
      "127/127 [==============================] - 26s 205ms/step - loss: 0.0348 - accuracy: 0.9867 - val_loss: 0.0305 - val_accuracy: 0.8741\n",
      "Epoch 115/200\n",
      "127/127 [==============================] - 27s 214ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 0.4443 - val_accuracy: 0.8929\n",
      "Epoch 116/200\n",
      "127/127 [==============================] - 27s 209ms/step - loss: 0.0703 - accuracy: 0.9754 - val_loss: 1.7737 - val_accuracy: 0.8831\n",
      "Epoch 117/200\n",
      "127/127 [==============================] - 28s 223ms/step - loss: 0.0651 - accuracy: 0.9824 - val_loss: 1.6893 - val_accuracy: 0.8673\n",
      "Epoch 118/200\n",
      "127/127 [==============================] - 26s 203ms/step - loss: 0.0470 - accuracy: 0.9817 - val_loss: 0.6665 - val_accuracy: 0.8891\n",
      "Epoch 119/200\n",
      "127/127 [==============================] - 26s 204ms/step - loss: 0.0524 - accuracy: 0.9852 - val_loss: 0.8670 - val_accuracy: 0.8839\n",
      "Epoch 120/200\n",
      "127/127 [==============================] - 27s 212ms/step - loss: 0.0464 - accuracy: 0.9857 - val_loss: 0.0139 - val_accuracy: 0.8899\n",
      "Epoch 121/200\n",
      "127/127 [==============================] - 26s 206ms/step - loss: 0.0313 - accuracy: 0.9901 - val_loss: 0.1429 - val_accuracy: 0.8929\n",
      "Epoch 122/200\n",
      "127/127 [==============================] - 25s 197ms/step - loss: 0.0235 - accuracy: 0.9936 - val_loss: 0.3143 - val_accuracy: 0.9005\n",
      "Epoch 123/200\n",
      "127/127 [==============================] - 26s 201ms/step - loss: 0.0624 - accuracy: 0.9812 - val_loss: 1.1894 - val_accuracy: 0.8846\n",
      "Epoch 124/200\n",
      "127/127 [==============================] - 26s 205ms/step - loss: 0.0529 - accuracy: 0.9854 - val_loss: 0.0489 - val_accuracy: 0.8869\n",
      "Epoch 125/200\n",
      "127/127 [==============================] - 27s 211ms/step - loss: 0.0516 - accuracy: 0.9817 - val_loss: 0.0768 - val_accuracy: 0.8982\n",
      "Epoch 126/200\n",
      "127/127 [==============================] - 27s 210ms/step - loss: 0.0381 - accuracy: 0.9884 - val_loss: 0.5216 - val_accuracy: 0.8922\n",
      "Epoch 127/200\n",
      "127/127 [==============================] - 25s 197ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.5195 - val_accuracy: 0.8974\n",
      "Epoch 128/200\n",
      "127/127 [==============================] - 26s 201ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 1.3836 - val_accuracy: 0.8876\n",
      "Epoch 129/200\n",
      "127/127 [==============================] - 26s 203ms/step - loss: 0.0477 - accuracy: 0.9857 - val_loss: 0.5631 - val_accuracy: 0.9005\n",
      "Epoch 130/200\n",
      "127/127 [==============================] - 27s 213ms/step - loss: 0.0336 - accuracy: 0.9884 - val_loss: 1.2582 - val_accuracy: 0.8891\n",
      "Epoch 131/200\n",
      "127/127 [==============================] - 28s 222ms/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.3716 - val_accuracy: 0.8846\n",
      "Epoch 132/200\n",
      "127/127 [==============================] - 26s 204ms/step - loss: 0.0558 - accuracy: 0.9820 - val_loss: 1.1236 - val_accuracy: 0.8982\n",
      "Epoch 133/200\n",
      "127/127 [==============================] - 26s 208ms/step - loss: 0.0411 - accuracy: 0.9896 - val_loss: 1.0356 - val_accuracy: 0.8899\n",
      "Epoch 134/200\n",
      "127/127 [==============================] - 27s 215ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 0.5973 - val_accuracy: 0.9065\n",
      "Epoch 135/200\n",
      "127/127 [==============================] - 28s 218ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 0.3726 - val_accuracy: 0.8793\n",
      "Epoch 136/200\n",
      "127/127 [==============================] - 27s 216ms/step - loss: 0.0426 - accuracy: 0.9874 - val_loss: 0.6113 - val_accuracy: 0.8899\n",
      "Epoch 137/200\n",
      "127/127 [==============================] - 26s 204ms/step - loss: 0.0512 - accuracy: 0.9849 - val_loss: 0.5401 - val_accuracy: 0.8922\n",
      "Epoch 138/200\n",
      "127/127 [==============================] - 26s 205ms/step - loss: 0.0530 - accuracy: 0.9834 - val_loss: 0.3892 - val_accuracy: 0.8778\n",
      "Epoch 139/200\n",
      "127/127 [==============================] - 27s 209ms/step - loss: 0.0522 - accuracy: 0.9869 - val_loss: 0.9024 - val_accuracy: 0.8861\n",
      "Epoch 140/200\n",
      "127/127 [==============================] - 27s 215ms/step - loss: 0.0371 - accuracy: 0.9869 - val_loss: 0.2971 - val_accuracy: 0.8876\n",
      "Epoch 141/200\n",
      "127/127 [==============================] - 27s 215ms/step - loss: 0.0382 - accuracy: 0.9881 - val_loss: 0.5608 - val_accuracy: 0.8808\n",
      "Epoch 142/200\n",
      "127/127 [==============================] - 26s 201ms/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 0.0692 - val_accuracy: 0.8839\n",
      "Epoch 143/200\n",
      "127/127 [==============================] - 25s 201ms/step - loss: 0.0311 - accuracy: 0.9894 - val_loss: 0.5697 - val_accuracy: 0.8967\n",
      "Epoch 144/200\n",
      "127/127 [==============================] - 26s 207ms/step - loss: 0.0404 - accuracy: 0.9862 - val_loss: 0.3984 - val_accuracy: 0.8748\n",
      "Epoch 145/200\n",
      "127/127 [==============================] - 27s 213ms/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.4779 - val_accuracy: 0.8914\n",
      "Epoch 146/200\n",
      "127/127 [==============================] - 27s 216ms/step - loss: 0.0309 - accuracy: 0.9879 - val_loss: 0.9684 - val_accuracy: 0.8982\n",
      "Epoch 147/200\n",
      "127/127 [==============================] - 26s 201ms/step - loss: 0.0424 - accuracy: 0.9889 - val_loss: 0.6048 - val_accuracy: 0.8914\n",
      "Epoch 148/200\n",
      "127/127 [==============================] - 25s 199ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.6359 - val_accuracy: 0.8952\n",
      "Epoch 149/200\n",
      "127/127 [==============================] - 26s 206ms/step - loss: 0.0538 - accuracy: 0.9854 - val_loss: 0.2341 - val_accuracy: 0.8982\n",
      "Epoch 150/200\n",
      "127/127 [==============================] - 28s 222ms/step - loss: 0.0349 - accuracy: 0.9872 - val_loss: 0.5718 - val_accuracy: 0.8906\n",
      "Epoch 151/200\n",
      "127/127 [==============================] - 27s 213ms/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 1.0354 - val_accuracy: 0.8929\n",
      "Epoch 152/200\n",
      "127/127 [==============================] - 26s 202ms/step - loss: 0.0462 - accuracy: 0.9867 - val_loss: 1.8401 - val_accuracy: 0.8778\n",
      "Epoch 153/200\n",
      "127/127 [==============================] - 25s 196ms/step - loss: 0.0321 - accuracy: 0.9901 - val_loss: 2.3085 - val_accuracy: 0.9050\n",
      "Epoch 154/200\n",
      "127/127 [==============================] - 24s 188ms/step - loss: 0.0712 - accuracy: 0.9785 - val_loss: 0.1730 - val_accuracy: 0.8831\n",
      "Epoch 155/200\n",
      "127/127 [==============================] - 24s 188ms/step - loss: 0.0422 - accuracy: 0.9852 - val_loss: 0.1372 - val_accuracy: 0.8997\n",
      "Epoch 156/200\n",
      "127/127 [==============================] - 25s 194ms/step - loss: 0.0384 - accuracy: 0.9894 - val_loss: 0.7498 - val_accuracy: 0.8824\n",
      "Epoch 157/200\n",
      "127/127 [==============================] - 25s 193ms/step - loss: 0.0519 - accuracy: 0.9858 - val_loss: 0.5780 - val_accuracy: 0.8967\n",
      "Epoch 158/200\n",
      "127/127 [==============================] - 25s 197ms/step - loss: 0.0277 - accuracy: 0.9923 - val_loss: 0.0323 - val_accuracy: 0.8974\n",
      "Epoch 159/200\n",
      "127/127 [==============================] - 25s 199ms/step - loss: 0.0354 - accuracy: 0.9901 - val_loss: 0.4186 - val_accuracy: 0.8959\n",
      "Epoch 160/200\n",
      "127/127 [==============================] - 26s 204ms/step - loss: 0.0331 - accuracy: 0.9911 - val_loss: 0.2075 - val_accuracy: 0.8876\n",
      "Epoch 161/200\n",
      "127/127 [==============================] - 27s 212ms/step - loss: 0.0503 - accuracy: 0.9859 - val_loss: 1.2594 - val_accuracy: 0.8959\n",
      "Epoch 162/200\n",
      "127/127 [==============================] - 27s 210ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.6302 - val_accuracy: 0.8824\n",
      "Epoch 163/200\n",
      "127/127 [==============================] - 25s 197ms/step - loss: 0.0404 - accuracy: 0.9879 - val_loss: 2.0706 - val_accuracy: 0.8793\n",
      "Epoch 164/200\n",
      "127/127 [==============================] - 26s 207ms/step - loss: 0.0419 - accuracy: 0.9904 - val_loss: 0.8177 - val_accuracy: 0.8861\n",
      "Epoch 165/200\n",
      "127/127 [==============================] - 29s 226ms/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.2180 - val_accuracy: 0.8914\n",
      "Epoch 166/200\n",
      "127/127 [==============================] - 28s 222ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.1405 - val_accuracy: 0.8974\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 27s 214ms/step - loss: 0.0342 - accuracy: 0.9902 - val_loss: 1.1988 - val_accuracy: 0.8884\n",
      "Epoch 168/200\n",
      "127/127 [==============================] - 25s 200ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.9094 - val_accuracy: 0.9005\n",
      "Epoch 169/200\n",
      "127/127 [==============================] - 26s 201ms/step - loss: 0.0389 - accuracy: 0.9893 - val_loss: 0.6203 - val_accuracy: 0.8922\n",
      "Epoch 170/200\n",
      "127/127 [==============================] - 26s 206ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.6812 - val_accuracy: 0.8982\n",
      "Epoch 171/200\n",
      "127/127 [==============================] - 27s 210ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.2665 - val_accuracy: 0.8876\n",
      "Epoch 172/200\n",
      "127/127 [==============================] - 27s 213ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 2.4901 - val_accuracy: 0.8824\n",
      "Epoch 173/200\n",
      "127/127 [==============================] - 26s 201ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 1.1449 - val_accuracy: 0.8973\n",
      "Epoch 174/200\n",
      "127/127 [==============================] - 26s 203ms/step - loss: 0.0306 - accuracy: 0.9916 - val_loss: 0.1960 - val_accuracy: 0.8922\n",
      "Epoch 175/200\n",
      "127/127 [==============================] - 27s 209ms/step - loss: 0.0451 - accuracy: 0.9852 - val_loss: 0.4322 - val_accuracy: 0.8997\n",
      "Epoch 176/200\n",
      "127/127 [==============================] - 27s 214ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 1.0100 - val_accuracy: 0.9035\n",
      "Epoch 177/200\n",
      "127/127 [==============================] - 27s 216ms/step - loss: 0.0188 - accuracy: 0.9931 - val_loss: 0.4539 - val_accuracy: 0.9050\n",
      "Epoch 178/200\n",
      "127/127 [==============================] - 26s 206ms/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 3.3857 - val_accuracy: 0.8846\n",
      "Epoch 179/200\n",
      "127/127 [==============================] - 26s 201ms/step - loss: 0.0453 - accuracy: 0.9869 - val_loss: 1.3550 - val_accuracy: 0.8854\n",
      "Epoch 180/200\n",
      "127/127 [==============================] - 26s 208ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.1265 - val_accuracy: 0.8982\n",
      "Epoch 181/200\n",
      "127/127 [==============================] - 27s 210ms/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.7507 - val_accuracy: 0.9065\n",
      "Epoch 182/200\n",
      "127/127 [==============================] - 27s 213ms/step - loss: 0.0206 - accuracy: 0.9923 - val_loss: 1.0224 - val_accuracy: 0.8937\n",
      "Epoch 183/200\n",
      "127/127 [==============================] - 26s 204ms/step - loss: 0.0408 - accuracy: 0.9876 - val_loss: 1.3315 - val_accuracy: 0.8922\n",
      "Epoch 184/200\n",
      "127/127 [==============================] - 25s 199ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 0.0017 - val_accuracy: 0.8944\n",
      "Epoch 185/200\n",
      "127/127 [==============================] - 26s 204ms/step - loss: 0.0229 - accuracy: 0.9918 - val_loss: 0.6250 - val_accuracy: 0.8891\n",
      "Epoch 186/200\n",
      "127/127 [==============================] - 26s 207ms/step - loss: 0.0477 - accuracy: 0.9852 - val_loss: 1.7169 - val_accuracy: 0.8831\n",
      "Epoch 187/200\n",
      "127/127 [==============================] - 27s 214ms/step - loss: 0.0415 - accuracy: 0.9867 - val_loss: 0.4798 - val_accuracy: 0.8944\n",
      "Epoch 188/200\n",
      "127/127 [==============================] - 27s 216ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.7246 - val_accuracy: 0.8861\n",
      "Epoch 189/200\n",
      "127/127 [==============================] - 28s 220ms/step - loss: 0.0516 - accuracy: 0.9829 - val_loss: 0.7044 - val_accuracy: 0.8974\n",
      "Epoch 190/200\n",
      "127/127 [==============================] - 26s 207ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.6980 - val_accuracy: 0.8944\n",
      "Epoch 191/200\n",
      "127/127 [==============================] - 26s 203ms/step - loss: 0.0328 - accuracy: 0.9913 - val_loss: 0.5311 - val_accuracy: 0.8816\n",
      "Epoch 192/200\n",
      "127/127 [==============================] - 25s 195ms/step - loss: 0.0472 - accuracy: 0.9879 - val_loss: 3.7882 - val_accuracy: 0.8959\n",
      "Epoch 193/200\n",
      "127/127 [==============================] - 25s 194ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.5919 - val_accuracy: 0.8944\n",
      "Epoch 194/200\n",
      "127/127 [==============================] - 25s 200ms/step - loss: 0.0450 - accuracy: 0.9889 - val_loss: 0.5166 - val_accuracy: 0.8876\n",
      "Epoch 195/200\n",
      "127/127 [==============================] - 27s 212ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 1.0496 - val_accuracy: 0.9042\n",
      "Epoch 196/200\n",
      "127/127 [==============================] - 26s 204ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 1.8337 - val_accuracy: 0.8959\n",
      "Epoch 197/200\n",
      "127/127 [==============================] - 27s 212ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.0973 - val_accuracy: 0.8982\n",
      "Epoch 198/200\n",
      "127/127 [==============================] - 27s 212ms/step - loss: 0.0349 - accuracy: 0.9903 - val_loss: 1.2043 - val_accuracy: 0.8914\n",
      "Epoch 199/200\n",
      "127/127 [==============================] - 28s 220ms/step - loss: 0.0413 - accuracy: 0.9879 - val_loss: 1.0379 - val_accuracy: 0.8869\n",
      "Epoch 200/200\n",
      "127/127 [==============================] - 27s 212ms/step - loss: 0.0260 - accuracy: 0.9906 - val_loss: 0.6606 - val_accuracy: 0.9012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40851712226867676, 0.8958333134651184]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting keras model, no test gen for now\n",
    "train_step=train_generator.n//train_generator.batch_size\n",
    "valid_step=valid_generator.n//valid_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=train_step,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_step,\n",
    "                    epochs=200\n",
    ")\n",
    "model.evaluate_generator(generator=valid_generator, steps=valid_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3297 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=test,\n",
    "    directory=\"Test_song/Specto\",\n",
    "    x_col=\"ID\",\n",
    "    y_col=None,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(64,64))\n",
    "test_step=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 7s 65ms/step\n",
      "['drilling', 'dog_bark', 'drilling', 'dog_bark', 'street_music', 'jackhammer', 'jackhammer', 'children_playing', 'dog_bark', 'siren', 'dog_bark', 'siren', 'dog_bark', 'children_playing', 'street_music', 'siren', 'dog_bark', 'drilling', 'drilling', 'jackhammer']\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=test_step,\n",
    "verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "#Fetch labels from train gen for testing\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "print(predictions[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving the model\n",
    "model.save(\"mods.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('mods.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
